{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 用户输入->知识库的查询语句\n",
    "20210111 created    \n",
    "这个notebook是参加 DataWhale 组织的<知识图谱组队学习>的学习笔记.      \n",
    "原始的开源学习项目地址:     \n",
    "https://github.com/datawhalechina/team-learning-nlp/tree/master/KnowledgeGraph_Basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yanzf/下载/team-learning-nlp-master/KnowledgeGraph_Basic'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '(/home/yanzf/下载/QASystemOnMedicalGraph-master)'\n",
      "/home/yanzf/下载/team-learning-nlp-master/KnowledgeGraph_Basic\n"
     ]
    }
   ],
   "source": [
    "cd('/home/yanzf/下载/QASystemOnMedicalGraph-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、引言\n",
    "\n",
    "本部分任务主要是**将用户输入问答系统的自然语言转化成知识库的查询语句**，因此本文将分成两部分进行介绍。\n",
    "- 第一部分介绍任务所涉及的背景知识;\n",
    "- 第二部分则是相应的代码和其注释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、什么是问答系统？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 问答系统简介\n",
    "\n",
    "问答系统(Question Answering System，QA System)是用来回答人提出的自然语言问题的系统。根据划分标准不同，问答系统可以被分为各种不同的类型。\n",
    "\n",
    "* 问答系统从知识领域划分：\n",
    "  * 封闭领域：封闭领域系统专注于回答特定领域的问题，由于问题领域受限，系统有比较大的发挥空间，可以导入领域知识或将答案来源全部转换成结构性资料来有效提升系统的表现；\n",
    "  * 开放领域：开放领域系统则希望不设限问题的内容范围，因此其难度也相对较大。\n",
    "\n",
    "* 问答系统从实现方式划分：\n",
    "  * 基于流水线（pipeline）实现：如下图 1 所示，基于流水线实现的问答系统有四大核心模块，分别由自然语言理解（NLU）、对话状态跟踪器（DST）、对话策略（DPL）和自然语言生成（NLG）依次串联构成的一条流水线，各模块可独立设计，模块间协作完成任务。\n",
    "  * 基于端到端（end-to-end）实现：基于端到端实现的问答系统，主要是结合深度学习技术，通过海量数据训练，挖掘出从用户自然语言输入到系统自然语言输出的整体映射关系，而忽略中间过程的一种方法。但就目前工业界整体应用而言，工业界的问答系统目前大多采用的还是基于流水线实现的方式。\n",
    "\n",
    "![](img/20210111154207.png)\n",
    "\n",
    "> 图 1 基于流水线（pipeline）实现\n",
    "\n",
    "* 问答系统从答案来源划分：\n",
    "  * 「知识库问答」。是目前的研究热点。知识库问答（knowledge base question answering, KB-QA）即给定自然语言问题，通过对问题进行语义理解和解析，进而利用知识库进行查询、推理得出答案。如下图 2 所示：\n",
    "  * 「常问问题问答」；\n",
    "  * 「新闻问答」；\n",
    "  * 「网际网路问答」；\n",
    "\n",
    "![](img/10798244-afb41aa23fee13c7.png)\n",
    "> 图 2 知识库问答\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Query理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1  Query理解介绍\n",
    "\n",
    "Query理解 (QU，Query Understanding)，简单来说就是从词法、句法、语义三个层面对 Query 进行结构化解析。\n",
    "\n",
    "- 搜索 Query 理解包含的模块主要有：\n",
    "  - Query预处理\n",
    "  - Query纠错\n",
    "  - Query扩展\n",
    "  - Query归一\n",
    "  - 意图识别\n",
    "  - 槽值填充\n",
    "  - Term重要性分析；\n",
    "  - ...\n",
    "\n",
    "由于本任务后面代码主要涉及意图识别和槽位解析，因此这里仅对这两部分内容做介绍："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 意图识别\n",
    "   \n",
    "- 介绍：意图识别是用来检测用户当前输入的意图，通常其被建模为将一段自然语言文本分类为预先设定的一个或多个意图的文本分类任务。\n",
    "- 所用方法：和文本分类模型的方法大同小异，主要有：\n",
    "  - 基于词典模板的规则分类\n",
    "  - 传统的机器学习模型（文本特征工程+分类器）\n",
    "  - 深度学习模型（Fasttext、TextCNN、BiLSTM + Self-Attention、BERT等）\n",
    "\n",
    "![](img/10798244-467c5be884303091.png)\n",
    "> 图 3 意图识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 槽值填充\n",
    "\n",
    "- 介绍：槽值填充就是根据我们既定的一些结构化字段，将用户输入的信息中与其对应的部分提取出来。因此，槽值填充经常被建模为序列标注的任务。\n",
    "- 举例介绍：例如下图所示的 Query \"北京飞成都的机票\"，通过意图分类模型可以识别出 Query 的整体意图是订机票，在此基础上进一步语义解析出对应的出发地 Depart=\"北京\"，到达地 Arrive=\"成都\"，所以生成的形式化表达可以是：Ticket=Order(Depart,Arrive)，Depart={北京}，Arrive={成都}。\n",
    "\n",
    "![](img/10798244-25aa5d0560dfee1a.jpg)\n",
    "> 图 4 槽值填充\n",
    "\n",
    "- 序列标注的任务常用的模型有：【注：这部分内容，第二期知识图谱组队学习将进行介绍】\n",
    "  - 词典匹配；\n",
    "  - BiLSTM + CRF；\n",
    "  - IDCNN\n",
    "  - BERT等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、任务实践\n",
    "\n",
    "![](img/10798244-322785573485895d.png)\n",
    "> 图 5 基于知识图谱的问答系统框架\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、 主体类 EntityExtractor 框架介绍\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "import os\n",
    "import ahocorasick\n",
    "from sklearn.externals import joblib\n",
    "import jieba\n",
    "import numpy as np\n",
    "\n",
    "class EntityExtractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # 构造actree，加速过滤\n",
    "    def build_actree(self, wordlist):\n",
    "        \"\"\"\n",
    "        构造actree，加速过滤\n",
    "        :param wordlist:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "    # 模式匹配, 得到匹配的词和类型。如疾病，疾病别名，并发症，症状\n",
    "    def entity_reg(self, question):\n",
    "        \"\"\"\n",
    "        模式匹配, 得到匹配的词和类型。如疾病，疾病别名，并发症，症状\n",
    "        :param question:str\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 当全匹配失败时，就采用相似度计算来找相似的词\n",
    "    def find_sim_words(self, question):\n",
    "        \"\"\"\n",
    "        当全匹配失败时，就采用相似度计算来找相似的词\n",
    "        :param question:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 采用DP方法计算编辑距离\n",
    "    def editDistanceDP(self, s1, s2):\n",
    "        \"\"\"\n",
    "        采用DP方法计算编辑距离\n",
    "        :param s1:\n",
    "        :param s2:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 计算词语和字典中的词的相似度\n",
    "    def simCal(self, word, entities, flag):\n",
    "        \"\"\"\n",
    "        计算词语和字典中的词的相似度\n",
    "        相同字符的个数/min(|A|,|B|)   +  余弦相似度\n",
    "        :param word: str\n",
    "        :param entities:List\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 基于特征词分类\n",
    "    def check_words(self, wds, sent):\n",
    "        \"\"\"\n",
    "        基于特征词分类\n",
    "        :param wds:\n",
    "        :param sent:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 提取问题的TF-IDF特征\n",
    "    def tfidf_features(self, text, vectorizer):\n",
    "        \"\"\"\n",
    "        提取问题的TF-IDF特征\n",
    "        :param text:\n",
    "        :param vectorizer:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 提取问题的关键词特征\n",
    "    def other_features(self, text):\n",
    "        \"\"\"\n",
    "        提取问题的关键词特征\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 预测意图\n",
    "    def model_predict(self, x, model):\n",
    "        \"\"\"\n",
    "        预测意图\n",
    "        :param x:\n",
    "        :param model:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 实体抽取主函数\n",
    "    def extractor(self, question):\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、命名实体识别任务实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 命名实体识别整体思路介绍\n",
    "\n",
    "- step 1：对于用户的输入，先使用预先构建的疾病、疾病别名、并发症和症状的AC Tree进行匹配；\n",
    "- step 2：若全都无法匹配到相应实体，则使用结巴切词库对用户输入的文本进行切分；\n",
    "- step 3：然后将每一个词都去与疾病词库、疾病别名词库、并发症词库和症状词库中的词计算相似度得分（overlap score、余弦相似度分数和编辑距离分数），如果相似度得分超过0.7，则认为该词是这一类实体；\n",
    "- step 4：最后排序选取最相关的词作为实体（项目所有的实体类型如下图所示，但实体识别时仅使用了疾病、别名、并发症和症状四种实体）\n",
    "\n",
    "![](img/10798244-b593dcc06d95bb35.png)\n",
    "> 图 6 实体介绍\n",
    "\n",
    "本部分所有的代码都来自 entity_extractor.py 中的 EntityExtractor 类，为了方便讲解，对类内的内容进行重新组织注释\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 结合代码介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 构建 AC Tree\n",
    "\n",
    "先通过 entity_extractor.py 中 类 EntityExtractor 的 build_actree 函数构建AC Tree\n",
    "\n",
    "- 函数模块\n",
    "```python\n",
    "    def build_actree(self, wordlist):\n",
    "        \"\"\"\n",
    "        构造actree，加速过滤\n",
    "        :param wordlist:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        actree = ahocorasick.Automaton()\n",
    "        # 向树中添加单词\n",
    "        for index, word in enumerate(wordlist):\n",
    "            actree.add_word(word, (index, word))\n",
    "        actree.make_automaton()\n",
    "        return actree\n",
    "```\n",
    "\n",
    "- 函数调用模块\n",
    "```python\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.disease_path = cur_dir + 'disease_vocab.txt'\n",
    "        self.symptom_path = cur_dir + 'symptom_vocab.txt'\n",
    "        self.alias_path = cur_dir + 'alias_vocab.txt'\n",
    "        self.complication_path = cur_dir + 'complications_vocab.txt'\n",
    "\n",
    "        self.disease_entities = [w.strip() for w in open(self.disease_path, encoding='utf8') if w.strip()]\n",
    "        self.symptom_entities = [w.strip() for w in open(self.symptom_path, encoding='utf8') if w.strip()]\n",
    "        self.alias_entities = [w.strip() for w in open(self.alias_path, encoding='utf8') if w.strip()]\n",
    "        self.complication_entities = [w.strip() for w in open(self.complication_path, encoding='utf8') if w.strip()]\n",
    "\n",
    "        self.region_words = list(set(self.disease_entities+self.alias_entities+self.symptom_entities))\n",
    "\n",
    "        # 构造领域actree\n",
    "        self.disease_tree = self.build_actree(list(set(self.disease_entities)))\n",
    "        self.alias_tree = self.build_actree(list(set(self.alias_entities)))\n",
    "        self.symptom_tree = self.build_actree(list(set(self.symptom_entities)))\n",
    "        self.complication_tree = self.build_actree(list(set(self.complication_entities)))\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 使用AC Tree进行问句过滤\n",
    "\n",
    "- 函数模块\n",
    "```python\n",
    "    def entity_reg(self, question):\n",
    "        \"\"\"\n",
    "        模式匹配, 得到匹配的词和类型。如疾病，疾病别名，并发症，症状\n",
    "        :param question:str\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.result = {}\n",
    "\n",
    "        for i in self.disease_tree.iter(question):\n",
    "            word = i[1][1]\n",
    "            if \"Disease\" not in self.result:\n",
    "                self.result[\"Disease\"] = [word]\n",
    "            else:\n",
    "                self.result[\"Disease\"].append(word)\n",
    "\n",
    "        for i in self.alias_tree.iter(question):\n",
    "            word = i[1][1]\n",
    "            if \"Alias\" not in self.result:\n",
    "                self.result[\"Alias\"] = [word]\n",
    "            else:\n",
    "                self.result[\"Alias\"].append(word)\n",
    "\n",
    "        for i in self.symptom_tree.iter(question):\n",
    "            wd = i[1][1]\n",
    "            if \"Symptom\" not in self.result:\n",
    "                self.result[\"Symptom\"] = [wd]\n",
    "            else:\n",
    "                self.result[\"Symptom\"].append(wd)\n",
    "\n",
    "        for i in self.complication_tree.iter(question):\n",
    "            wd = i[1][1]\n",
    "            if \"Complication\" not in self.result:\n",
    "                self.result[\"Complication\"] = [wd]\n",
    "            else:\n",
    "                self.result[\"Complication\"] .append(wd)\n",
    "\n",
    "        return self.result\n",
    "```\n",
    "- 函数调用模块\n",
    "```python\n",
    "    def extractor(self, question):\n",
    "        self.entity_reg(question)\n",
    "        ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 使用 相似度进行实体匹配\n",
    "\n",
    "当AC Tree的匹配都没有匹配到实体时，使用查找相似词的方式进行实体匹配\n",
    "\n",
    "```python\n",
    "def find_sim_words(self, question):\n",
    "    \"\"\"\n",
    "    当全匹配失败时，就采用相似度计算来找相似的词\n",
    "    :param question:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import string\n",
    "    from gensim.models import KeyedVectors\n",
    "    \n",
    "    # 使用结巴加载自定义词典\n",
    "    jieba.load_userdict(self.vocab_path)\n",
    "    # 加载词向量\n",
    "    self.model = KeyedVectors.load_word2vec_format(self.word2vec_path, binary=False)\n",
    "    \n",
    "    # 数据预处理，正则去除特殊符号\n",
    "    sentence = re.sub(\"[{}]\", re.escape(string.punctuation), question)\n",
    "    sentence = re.sub(\"[，。‘’；：？、！【】]\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 使用结巴进行分词\n",
    "    words = [w.strip() for w in jieba.cut(sentence) if w.strip() not in self.stopwords and len(w.strip()) >= 2]\n",
    "\n",
    "    alist = []\n",
    "    \n",
    "    # 对每个词，都让其与每类实体词典进行相似对比，\n",
    "    # 最终选取分数最高的实体和其属于的实体类型\n",
    "    for word in words:\n",
    "        temp = [self.disease_entities, self.alias_entities, self.symptom_entities, self.complication_entities]\n",
    "        for i in range(len(temp)):\n",
    "            flag = ''\n",
    "            if i == 0:\n",
    "                flag = \"Disease\"\n",
    "            elif i == 1:\n",
    "                flag = \"Alias\"\n",
    "            elif i == 2:\n",
    "                flag = \"Symptom\"\n",
    "            else:\n",
    "                flag = \"Complication\"\n",
    "            scores = self.simCal(word, temp[i], flag)\n",
    "            alist.extend(scores)\n",
    "    temp1 = sorted(alist, key=lambda k: k[1], reverse=True)\n",
    "    if temp1:\n",
    "        self.result[temp1[0][2]] = [temp1[0][0]]\n",
    "\n",
    "# 计算词语和字典中的词的相似度\n",
    "def simCal(self, word, entities, flag):\n",
    "    \"\"\"\n",
    "    计算词语和字典中的词的相似度\n",
    "    相同字符的个数/min(|A|,|B|)   +  余弦相似度\n",
    "    :param word: str\n",
    "    :param entities:List\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    a = len(word)\n",
    "    scores = []\n",
    "    for entity in entities:\n",
    "        sim_num = 0\n",
    "        b = len(entity)\n",
    "        c = len(set(entity+word))\n",
    "        temp = []\n",
    "        for w in word:\n",
    "            if w in entity:\n",
    "                sim_num += 1\n",
    "        if sim_num != 0:\n",
    "            score1 = sim_num / c  # overlap score\n",
    "            temp.append(score1)\n",
    "        try:\n",
    "            score2 = self.model.similarity(word, entity)  # 余弦相似度分数\n",
    "            temp.append(score2)\n",
    "        except:\n",
    "            pass\n",
    "        score3 = 1 - self.editDistanceDP(word, entity) / (a + b)  # 编辑距离分数\n",
    "        if score3:\n",
    "            temp.append(score3)\n",
    "\n",
    "        score = sum(temp) / len(temp)\n",
    "        if score >= 0.7:\n",
    "            scores.append((entity, score, flag))\n",
    "\n",
    "    scores.sort(key=lambda k: k[1], reverse=True)\n",
    "    return scores\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、意图识别任务实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 意图识别整体思路介绍\n",
    "\n",
    "- step 1：利用TF-IDF表征文本特征，同时构建一些人工特征（每一类意图常见词在句子中出现的个数）；\n",
    "- step 2：训练朴素贝叶斯模型进行意图识别任务；\n",
    "- step 3：使用实体信息进行意图的纠正和补充。\n",
    "\n",
    "![](img/10798244-6113c647b881e4aa.png)\n",
    "> 图 7 意图识别整体举例介绍\n",
    "\n",
    "该项目通过手工标记210条意图分类训练数据，并采用朴素贝叶斯算法训练得到意图分类模型。其最佳测试效果的F1值达到了96.68%。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 意图识别整体思路介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.1 特征构建\n",
    "\n",
    "1. TF-IDF特征\n",
    "```python\n",
    "# 提取问题的TF-IDF特征\n",
    "def tfidf_features(self, text, vectorizer):\n",
    "    \"\"\"\n",
    "    提取问题的TF-IDF特征\n",
    "    :param text:\n",
    "    :param vectorizer:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    jieba.load_userdict(self.vocab_path)\n",
    "    words = [w.strip() for w in jieba.cut(text) if w.strip() and w.strip() not in self.stopwords]\n",
    "    sents = [' '.join(words)]\n",
    "\n",
    "    tfidf = vectorizer.transform(sents).toarray()\n",
    "    return tfidf\n",
    "```\n",
    "2. 人工特征\n",
    "```python\t    \n",
    "self.symptom_qwds = ['什么症状', '哪些症状', '症状有哪些', '症状是什么', '什么表征', '哪些表征', '表征是什么',\n",
    "                     '什么现象', '哪些现象', '现象有哪些', '症候', '什么表现', '哪些表现', '表现有哪些',\n",
    "                     '什么行为', '哪些行为', '行为有哪些', '什么状况', '哪些状况', '状况有哪些', '现象是什么',\n",
    "                     '表现是什么', '行为是什么']  # 询问症状\n",
    "self.cureway_qwds = ['药', '药品', '用药', '胶囊', '口服液', '炎片', '吃什么药', '用什么药', '怎么办',\n",
    "                     '买什么药', '怎么治疗', '如何医治', '怎么医治', '怎么治', '怎么医', '如何治',\n",
    "                     '医治方式', '疗法', '咋治', '咋办', '咋治', '治疗方法']  # 询问治疗方法\n",
    "self.lasttime_qwds = ['周期', '多久', '多长时间', '多少时间', '几天', '几年', '多少天', '多少小时',\n",
    "                      '几个小时', '多少年', '多久能好', '痊愈', '康复']  # 询问治疗周期\n",
    "self.cureprob_qwds = ['多大概率能治好', '多大几率能治好', '治好希望大么', '几率', '几成', '比例',\n",
    "                      '可能性', '能治', '可治', '可以治', '可以医', '能治好吗', '可以治好吗', '会好吗',\n",
    "                      '能好吗', '治愈吗']  # 询问治愈率\n",
    "self.check_qwds = ['检查什么', '检查项目', '哪些检查', '什么检查', '检查哪些', '项目', '检测什么',\n",
    "                   '哪些检测', '检测哪些', '化验什么', '哪些化验', '化验哪些', '哪些体检', '怎么查找',\n",
    "                   '如何查找', '怎么检查', '如何检查', '怎么检测', '如何检测']  # 询问检查项目\n",
    "self.belong_qwds = ['属于什么科', '什么科', '科室', '挂什么', '挂哪个', '哪个科', '哪些科']  # 询问科室\n",
    "self.disase_qwds = ['什么病', '啥病', '得了什么', '得了哪种', '怎么回事', '咋回事', '回事',\n",
    "                    '什么情况', '什么问题', '什么毛病', '啥毛病', '哪种病']  # 询问疾病\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "def other_features(self, text):\n",
    "\t\"\"\"\n",
    "\t提取问题的关键词特征\n",
    "\t:param text:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tfeatures = [0] * 7\n",
    "\tfor d in self.disase_qwds:\n",
    "\t    if d in text:\n",
    "\t        features[0] += 1\n",
    "\t\n",
    "\tfor s in self.symptom_qwds:\n",
    "\t    if s in text:\n",
    "\t        features[1] += 1\n",
    "\t\n",
    "\tfor c in self.cureway_qwds:\n",
    "\t    if c in text:\n",
    "\t        features[2] += 1\n",
    "\t\n",
    "\tfor c in self.check_qwds:\n",
    "\t    if c in text:\n",
    "\t        features[3] += 1\n",
    "\tfor p in self.lasttime_qwds:\n",
    "\t    if p in text:\n",
    "\t        features[4] += 1\n",
    "\t\n",
    "\tfor r in self.cureprob_qwds:\n",
    "\t    if r in text:\n",
    "\t        features[5] += 1\n",
    "\t\n",
    "\tfor d in self.belong_qwds:\n",
    "\t    if d in text:\n",
    "\t        features[6] += 1\n",
    "\t\n",
    "\tm = max(features)\n",
    "\tn = min(features)\n",
    "\tnormed_features = []\n",
    "\tif m == n:\n",
    "\t    normed_features = features\n",
    "\telse:\n",
    "\t    for i in features:\n",
    "\t        j = (i - n) / (m - n)\n",
    "\t        normed_features.append(j)\n",
    "\t\n",
    "\treturn np.array(normed_features)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2 使用朴素贝叶斯进行文本分类\n",
    "- 项目没有给出训练过程，可参考下面sklearn的例子\n",
    "```python\n",
    "    # 项目没有给出训练过程，可参考下面sklearn的例子\n",
    "    from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "    mnb = MultinomialNB()   \n",
    "    mnb.fit(X_train,y_train)   \n",
    "    y_predict = mnb.predict(X_test)\n",
    "\n",
    "    # 意图分类模型文件\n",
    "    self.tfidf_path = os.path.join(cur_dir, 'model/tfidf_model.m')\n",
    "    self.nb_path = os.path.join(cur_dir, 'model/intent_reg_model.m')  #朴素贝叶斯模型\n",
    "    self.tfidf_model = joblib.load(self.tfidf_path)\n",
    "    self.nb_model = joblib.load(self.nb_path)\n",
    "\n",
    "    # 意图预测\n",
    "    tfidf_feature = self.tfidf_features(question, self.tfidf_model)\n",
    "\n",
    "    other_feature = self.other_features(question)\n",
    "    m = other_feature.shape\n",
    "    other_feature = np.reshape(other_feature, (1, m[0]))\n",
    "    feature = np.concatenate((tfidf_feature, other_feature), axis=1)\n",
    "    predicted = self.model_predict(feature, self.nb_model)\n",
    "    intentions.append(predicted[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-根据所识别的实体进行补充和纠正意图\n",
    "```python\n",
    "# 已知疾病，查询症状\n",
    "if self.check_words(self.symptom_qwds, question) and ('Disease' in types or 'Alia' in types):\n",
    "    intention = \"query_symptom\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "# 已知疾病或症状，查询治疗方法\n",
    "if self.check_words(self.cureway_qwds, question) and \\\n",
    "        ('Disease' in types or 'Symptom' in types or 'Alias' in types or 'Complication' in types):\n",
    "    intention = \"query_cureway\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "# 已知疾病或症状，查询治疗周期\n",
    "if self.check_words(self.lasttime_qwds, question) and ('Disease' in types or 'Alia' in types):\n",
    "    intention = \"query_period\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "# 已知疾病，查询治愈率\n",
    "if self.check_words(self.cureprob_qwds, question) and ('Disease' in types or 'Alias' in types):\n",
    "    intention = \"query_rate\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "# 已知疾病，查询检查项目\n",
    "if self.check_words(self.check_qwds, question) and ('Disease' in types or 'Alias' in types):\n",
    "    intention = \"query_checklist\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "# 查询科室\n",
    "if self.check_words(self.belong_qwds, question) and \\\n",
    "        ('Disease' in types or 'Symptom' in types or 'Alias' in types or 'Complication' in types):\n",
    "    intention = \"query_department\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "# 已知症状，查询疾病\n",
    "if self.check_words(self.disase_qwds, question) and (\"Symptom\" in types or \"Complication\" in types):\n",
    "    intention = \"query_disease\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "\n",
    "# 若没有检测到意图，且已知疾病，则返回疾病的描述\n",
    "if not intentions and ('Disease' in types or 'Alias' in types):\n",
    "    intention = \"disease_describe\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "# 若是疾病和症状同时出现，且出现了查询疾病的特征词，则意图为查询疾病\n",
    "if self.check_words(self.disase_qwds, question) and ('Disease' in types or 'Alias' in types) \\\n",
    "        and (\"Symptom\" in types or \"Complication\" in types):\n",
    "    intention = \"query_disease\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "# 若没有识别出实体或意图则调用其它方法\n",
    "if not intentions or not types:\n",
    "    intention = \"QA_matching\"\n",
    "    if intention not in intentions:\n",
    "        intentions.append(intention)\n",
    "\n",
    "self.result[\"intentions\"] = intentions\n",
    "\n",
    "```\n",
    "\n",
    "后续就是通过上述得到的意图信息和实体信息选择对应的模版，并将实体信息填充入组成查询语句进行数据库查询。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考资料 \n",
    "\n",
    "1. [ QASystemOnMedicalGraph](https://github.com/zhihao-chen/QASystemOnMedicalGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "以下内容是代码实践部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装 ahocorasick\n",
    "#conda install -c https://conda.anaconda.org/conda-forge pyahocorasick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* entity_extractor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "import os\n",
    "import ahocorasick\n",
    "#from sklearn.externals import joblib #新版本的 sklearn 需要使用 import joblib\n",
    "import joblib\n",
    "import jieba\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yanzf/下载/team-learning-nlp-master/KnowledgeGraph_Basic'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看当前工作目录\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yanzf/下载/team-learning-nlp-master/KnowledgeGraph_Basic'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#直接运行该代码会报错,提示__file__未定义,准备改写这部分\n",
    "#首先测试 entity_extractor.py 代码中的目录获取语句\n",
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yanzf/下载/team-learning-nlp-master'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#再测试 entity_extractor.py 代码中的目录获取语句\n",
    "'/'.join(os.getcwd().split('/')[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 entity_extractor.py 代码中的目录获取部分的语句替换为真实的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityExtractor:\n",
    "    def __init__(self):\n",
    "        #cur_dir = '/'.join(os.path.abspath(__file__).split('/')[:-1])\n",
    "        cur_dir = \"/home/yanzf/下载/QASystemOnMedicalGraph-master/\" #文件路径替换为真实的路径\n",
    "        # 路径\n",
    "        self.vocab_path = os.path.join(cur_dir, 'data/vocab.txt')\n",
    "        self.stopwords_path =os.path.join(cur_dir, 'data/stop_words.utf8')\n",
    "        self.word2vec_path = os.path.join(cur_dir, 'data/merge_sgns_bigram_char300.txt')\n",
    "        # self.same_words_path = os.path.join(cur_dir, 'DATA/同义词林.txt')\n",
    "        self.stopwords = [w.strip() for w in open(self.stopwords_path, 'r', encoding='utf8') if w.strip()]\n",
    "\n",
    "        # 意图分类模型文件\n",
    "        self.tfidf_path = os.path.join(cur_dir, 'model/tfidf_model.m')\n",
    "        self.nb_path = os.path.join(cur_dir, 'model/intent_reg_model.m')  #朴素贝叶斯模型\n",
    "        self.tfidf_model = joblib.load(self.tfidf_path)\n",
    "        self.nb_model = joblib.load(self.nb_path)\n",
    "\n",
    "        self.disease_path = data_dir + 'disease_vocab.txt'\n",
    "        self.symptom_path = data_dir + 'symptom_vocab.txt'\n",
    "        self.alias_path = data_dir + 'alias_vocab.txt'\n",
    "        self.complication_path = data_dir + 'complications_vocab.txt'\n",
    "\n",
    "        self.disease_entities = [w.strip() for w in open(self.disease_path, encoding='utf8') if w.strip()]\n",
    "        self.symptom_entities = [w.strip() for w in open(self.symptom_path, encoding='utf8') if w.strip()]\n",
    "        self.alias_entities = [w.strip() for w in open(self.alias_path, encoding='utf8') if w.strip()]\n",
    "        self.complication_entities = [w.strip() for w in open(self.complication_path, encoding='utf8') if w.strip()]\n",
    "\n",
    "        self.region_words = list(set(self.disease_entities+self.alias_entities+self.symptom_entities))\n",
    "\n",
    "        # 构造领域actree\n",
    "        self.disease_tree = self.build_actree(list(set(self.disease_entities)))\n",
    "        self.alias_tree = self.build_actree(list(set(self.alias_entities)))\n",
    "        self.symptom_tree = self.build_actree(list(set(self.symptom_entities)))\n",
    "        self.complication_tree = self.build_actree(list(set(self.complication_entities)))\n",
    "\n",
    "        self.symptom_qwds = ['什么症状', '哪些症状', '症状有哪些', '症状是什么', '什么表征', '哪些表征', '表征是什么',\n",
    "                             '什么现象', '哪些现象', '现象有哪些', '症候', '什么表现', '哪些表现', '表现有哪些',\n",
    "                             '什么行为', '哪些行为', '行为有哪些', '什么状况', '哪些状况', '状况有哪些', '现象是什么',\n",
    "                             '表现是什么', '行为是什么']  # 询问症状\n",
    "        self.cureway_qwds = ['药', '药品', '用药', '胶囊', '口服液', '炎片', '吃什么药', '用什么药', '怎么办',\n",
    "                             '买什么药', '怎么治疗', '如何医治', '怎么医治', '怎么治', '怎么医', '如何治',\n",
    "                             '医治方式', '疗法', '咋治', '咋办', '咋治', '治疗方法']  # 询问治疗方法\n",
    "        self.lasttime_qwds = ['周期', '多久', '多长时间', '多少时间', '几天', '几年', '多少天', '多少小时',\n",
    "                              '几个小时', '多少年', '多久能好', '痊愈', '康复']  # 询问治疗周期\n",
    "        self.cureprob_qwds = ['多大概率能治好', '多大几率能治好', '治好希望大么', '几率', '几成', '比例',\n",
    "                              '可能性', '能治', '可治', '可以治', '可以医', '能治好吗', '可以治好吗', '会好吗',\n",
    "                              '能好吗', '治愈吗']  # 询问治愈率\n",
    "        self.check_qwds = ['检查什么', '检查项目', '哪些检查', '什么检查', '检查哪些', '项目', '检测什么',\n",
    "                           '哪些检测', '检测哪些', '化验什么', '哪些化验', '化验哪些', '哪些体检', '怎么查找',\n",
    "                           '如何查找', '怎么检查', '如何检查', '怎么检测', '如何检测']  # 询问检查项目\n",
    "        self.belong_qwds = ['属于什么科', '什么科', '科室', '挂什么', '挂哪个', '哪个科', '哪些科']  # 询问科室\n",
    "        self.disase_qwds = ['什么病', '啥病', '得了什么', '得了哪种', '怎么回事', '咋回事', '回事',\n",
    "                            '什么情况', '什么问题', '什么毛病', '啥毛病', '哪种病']  # 询问疾病\n",
    "\n",
    "    def build_actree(self, wordlist):\n",
    "        \"\"\"\n",
    "        构造actree，加速过滤\n",
    "        :param wordlist:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        actree = ahocorasick.Automaton()\n",
    "        # 向树中添加单词\n",
    "        for index, word in enumerate(wordlist):\n",
    "            actree.add_word(word, (index, word))\n",
    "        actree.make_automaton()\n",
    "        return actree\n",
    "\n",
    "    def entity_reg(self, question):\n",
    "        \"\"\"\n",
    "        模式匹配, 得到匹配的词和类型。如疾病，疾病别名，并发症，症状\n",
    "        :param question:str\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.result = {}\n",
    "\n",
    "        for i in self.disease_tree.iter(question):\n",
    "            word = i[1][1]\n",
    "            if \"Disease\" not in self.result:\n",
    "                self.result[\"Disease\"] = [word]\n",
    "            else:\n",
    "                self.result[\"Disease\"].append(word)\n",
    "\n",
    "        for i in self.alias_tree.iter(question):\n",
    "            word = i[1][1]\n",
    "            if \"Alias\" not in self.result:\n",
    "                self.result[\"Alias\"] = [word]\n",
    "            else:\n",
    "                self.result[\"Alias\"].append(word)\n",
    "\n",
    "        for i in self.symptom_tree.iter(question):\n",
    "            wd = i[1][1]\n",
    "            if \"Symptom\" not in self.result:\n",
    "                self.result[\"Symptom\"] = [wd]\n",
    "            else:\n",
    "                self.result[\"Symptom\"].append(wd)\n",
    "\n",
    "        for i in self.complication_tree.iter(question):\n",
    "            wd = i[1][1]\n",
    "            if \"Complication\" not in self.result:\n",
    "                self.result[\"Complication\"] = [wd]\n",
    "            else:\n",
    "                self.result[\"Complication\"] .append(wd)\n",
    "\n",
    "        return self.result\n",
    "\n",
    "    def find_sim_words(self, question):\n",
    "        \"\"\"\n",
    "        当全匹配失败时，就采用相似度计算来找相似的词\n",
    "        :param question:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        import re\n",
    "        import string\n",
    "        from gensim.models import KeyedVectors\n",
    "\n",
    "        jieba.load_userdict(self.vocab_path)\n",
    "        self.model = KeyedVectors.load_word2vec_format(self.word2vec_path, binary=False)\n",
    "\n",
    "        sentence = re.sub(\"[{}]\", re.escape(string.punctuation), question)\n",
    "        sentence = re.sub(\"[，。‘’；：？、！【】]\", \" \", sentence)\n",
    "        sentence = sentence.strip()\n",
    "\n",
    "        words = [w.strip() for w in jieba.cut(sentence) if w.strip() not in self.stopwords and len(w.strip()) >= 2]\n",
    "\n",
    "        alist = []\n",
    "\n",
    "        for word in words:\n",
    "            temp = [self.disease_entities, self.alias_entities, self.symptom_entities, self.complication_entities]\n",
    "            for i in range(len(temp)):\n",
    "                flag = ''\n",
    "                if i == 0:\n",
    "                    flag = \"Disease\"\n",
    "                elif i == 1:\n",
    "                    flag = \"Alias\"\n",
    "                elif i == 2:\n",
    "                    flag = \"Symptom\"\n",
    "                else:\n",
    "                    flag = \"Complication\"\n",
    "                scores = self.simCal(word, temp[i], flag)\n",
    "                alist.extend(scores)\n",
    "        temp1 = sorted(alist, key=lambda k: k[1], reverse=True)\n",
    "        if temp1:\n",
    "            self.result[temp1[0][2]] = [temp1[0][0]]\n",
    "\n",
    "    def editDistanceDP(self, s1, s2):\n",
    "        \"\"\"\n",
    "        采用DP方法计算编辑距离\n",
    "        :param s1:\n",
    "        :param s2:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        m = len(s1)\n",
    "        n = len(s2)\n",
    "        solution = [[0 for j in range(n + 1)] for i in range(m + 1)]\n",
    "        for i in range(len(s2) + 1):\n",
    "            solution[0][i] = i\n",
    "        for i in range(len(s1) + 1):\n",
    "            solution[i][0] = i\n",
    "\n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, n + 1):\n",
    "                if s1[i - 1] == s2[j - 1]:\n",
    "                    solution[i][j] = solution[i - 1][j - 1]\n",
    "                else:\n",
    "                    solution[i][j] = 1 + min(solution[i][j - 1], min(solution[i - 1][j],\n",
    "                                                                     solution[i - 1][j - 1]))\n",
    "        return solution[m][n]\n",
    "\n",
    "    def simCal(self, word, entities, flag):\n",
    "        \"\"\"\n",
    "        计算词语和字典中的词的相似度\n",
    "        相同字符的个数/min(|A|,|B|)   +  余弦相似度\n",
    "        :param word: str\n",
    "        :param entities:List\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        a = len(word)\n",
    "        scores = []\n",
    "        for entity in entities:\n",
    "            sim_num = 0\n",
    "            b = len(entity)\n",
    "            c = len(set(entity+word))\n",
    "            temp = []\n",
    "            for w in word:\n",
    "                if w in entity:\n",
    "                    sim_num += 1\n",
    "            if sim_num != 0:\n",
    "                score1 = sim_num / c  # overlap score\n",
    "                temp.append(score1)\n",
    "            try:\n",
    "                score2 = self.model.similarity(word, entity)  # 余弦相似度分数\n",
    "                temp.append(score2)\n",
    "            except:\n",
    "                pass\n",
    "            score3 = 1 - self.editDistanceDP(word, entity) / (a + b)  # 编辑距离分数\n",
    "            if score3:\n",
    "                temp.append(score3)\n",
    "\n",
    "            score = sum(temp) / len(temp)\n",
    "            if score >= 0.7:\n",
    "                scores.append((entity, score, flag))\n",
    "\n",
    "        scores.sort(key=lambda k: k[1], reverse=True)\n",
    "        return scores\n",
    "\n",
    "    def check_words(self, wds, sent):\n",
    "        \"\"\"\n",
    "        基于特征词分类\n",
    "        :param wds:\n",
    "        :param sent:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for wd in wds:\n",
    "            if wd in sent:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def tfidf_features(self, text, vectorizer):\n",
    "        \"\"\"\n",
    "        提取问题的TF-IDF特征\n",
    "        :param text:\n",
    "        :param vectorizer:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        jieba.load_userdict(self.vocab_path)\n",
    "        words = [w.strip() for w in jieba.cut(text) if w.strip() and w.strip() not in self.stopwords]\n",
    "        sents = [' '.join(words)]\n",
    "\n",
    "        tfidf = vectorizer.transform(sents).toarray()\n",
    "        return tfidf\n",
    "\n",
    "    def other_features(self, text):\n",
    "        \"\"\"\n",
    "        提取问题的关键词特征\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        features = [0] * 7\n",
    "        for d in self.disase_qwds:\n",
    "            if d in text:\n",
    "                features[0] += 1\n",
    "\n",
    "        for s in self.symptom_qwds:\n",
    "            if s in text:\n",
    "                features[1] += 1\n",
    "\n",
    "        for c in self.cureway_qwds:\n",
    "            if c in text:\n",
    "                features[2] += 1\n",
    "\n",
    "        for c in self.check_qwds:\n",
    "            if c in text:\n",
    "                features[3] += 1\n",
    "        for p in self.lasttime_qwds:\n",
    "            if p in text:\n",
    "                features[4] += 1\n",
    "\n",
    "        for r in self.cureprob_qwds:\n",
    "            if r in text:\n",
    "                features[5] += 1\n",
    "\n",
    "        for d in self.belong_qwds:\n",
    "            if d in text:\n",
    "                features[6] += 1\n",
    "\n",
    "        m = max(features)\n",
    "        n = min(features)\n",
    "        normed_features = []\n",
    "        if m == n:\n",
    "            normed_features = features\n",
    "        else:\n",
    "            for i in features:\n",
    "                j = (i - n) / (m - n)\n",
    "                normed_features.append(j)\n",
    "\n",
    "        return np.array(normed_features)\n",
    "\n",
    "    def model_predict(self, x, model):\n",
    "        \"\"\"\n",
    "        预测意图\n",
    "        :param x:\n",
    "        :param model:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pred = model.predict(x)\n",
    "        return pred\n",
    "\n",
    "    # 实体抽取主函数\n",
    "    def extractor(self, question):\n",
    "        self.entity_reg(question)\n",
    "        if not self.result:\n",
    "            self.find_sim_words(question)\n",
    "\n",
    "        types = []  # 实体类型\n",
    "        for v in self.result.keys():\n",
    "            types.append(v)\n",
    "\n",
    "        intentions = []  # 查询意图\n",
    "\n",
    "        # 意图预测\n",
    "        tfidf_feature = self.tfidf_features(question, self.tfidf_model)\n",
    "\n",
    "        other_feature = self.other_features(question)\n",
    "        m = other_feature.shape\n",
    "        other_feature = np.reshape(other_feature, (1, m[0]))\n",
    "\n",
    "        feature = np.concatenate((tfidf_feature, other_feature), axis=1)\n",
    "\n",
    "        predicted = self.model_predict(feature, self.nb_model)\n",
    "        intentions.append(predicted[0])\n",
    "\n",
    "        # 已知疾病，查询症状\n",
    "        if self.check_words(self.symptom_qwds, question) and ('Disease' in types or 'Alia' in types):\n",
    "            intention = \"query_symptom\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "        # 已知疾病或症状，查询治疗方法\n",
    "        if self.check_words(self.cureway_qwds, question) and \\\n",
    "                ('Disease' in types or 'Symptom' in types or 'Alias' in types or 'Complication' in types):\n",
    "            intention = \"query_cureway\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "        # 已知疾病或症状，查询治疗周期\n",
    "        if self.check_words(self.lasttime_qwds, question) and ('Disease' in types or 'Alia' in types):\n",
    "            intention = \"query_period\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "        # 已知疾病，查询治愈率\n",
    "        if self.check_words(self.cureprob_qwds, question) and ('Disease' in types or 'Alias' in types):\n",
    "            intention = \"query_rate\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "        # 已知疾病，查询检查项目\n",
    "        if self.check_words(self.check_qwds, question) and ('Disease' in types or 'Alias' in types):\n",
    "            intention = \"query_checklist\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "        # 查询科室\n",
    "        if self.check_words(self.belong_qwds, question) and \\\n",
    "                ('Disease' in types or 'Symptom' in types or 'Alias' in types or 'Complication' in types):\n",
    "            intention = \"query_department\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "        # 已知症状，查询疾病\n",
    "        if self.check_words(self.disase_qwds, question) and (\"Symptom\" in types or \"Complication\" in types):\n",
    "            intention = \"query_disease\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "\n",
    "        # 若没有检测到意图，且已知疾病，则返回疾病的描述\n",
    "        if not intentions and ('Disease' in types or 'Alias' in types):\n",
    "            intention = \"disease_describe\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "        # 若是疾病和症状同时出现，且出现了查询疾病的特征词，则意图为查询疾病\n",
    "        if self.check_words(self.disase_qwds, question) and ('Disease' in types or 'Alias' in types) \\\n",
    "                and (\"Symptom\" in types or \"Complication\" in types):\n",
    "            intention = \"query_disease\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "        # 若没有识别出实体或意图则调用其它方法\n",
    "        if not intentions or not types:\n",
    "            intention = \"QA_matching\"\n",
    "            if intention not in intentions:\n",
    "                intentions.append(intention)\n",
    "\n",
    "        self.result[\"intentions\"] = intentions\n",
    "\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* search_answer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "from py2neo import Graph\n",
    "\n",
    "\n",
    "class AnswerSearching:\n",
    "    def __init__(self):\n",
    "        self.graph = Graph(\"http://localhost:7474\", username=\"neo4j\", password=\"123456789\")\n",
    "        self.top_num = 10\n",
    "\n",
    "    def question_parser(self, data):\n",
    "        \"\"\"\n",
    "        主要是根据不同的实体和意图构造cypher查询语句\n",
    "        :param data: {\"Disease\":[], \"Alias\":[], \"Symptom\":[], \"Complication\":[]}\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        sqls = []\n",
    "        if data:\n",
    "            for intent in data[\"intentions\"]:\n",
    "                sql_ = {}\n",
    "                sql_[\"intention\"] = intent\n",
    "                sql = []\n",
    "                if data.get(\"Disease\"):\n",
    "                   sql = self.transfor_to_sql(\"Disease\", data[\"Disease\"], intent)\n",
    "                elif data.get(\"Alias\"):\n",
    "                    sql = self.transfor_to_sql(\"Alias\", data[\"Alias\"], intent)\n",
    "                elif data.get(\"Symptom\"):\n",
    "                    sql = self.transfor_to_sql(\"Symptom\", data[\"Symptom\"], intent)\n",
    "                elif data.get(\"Complication\"):\n",
    "                    sql = self.transfor_to_sql(\"Complication\", data[\"Complication\"], intent)\n",
    "\n",
    "                if sql:\n",
    "                    sql_['sql'] = sql\n",
    "                    sqls.append(sql_)\n",
    "        return sqls\n",
    "\n",
    "    def transfor_to_sql(self, label, entities, intent):\n",
    "        \"\"\"\n",
    "        将问题转变为cypher查询语句\n",
    "        :param label:实体标签\n",
    "        :param entities:实体列表\n",
    "        :param intent:查询意图\n",
    "        :return:cypher查询语句\n",
    "        \"\"\"\n",
    "        if not entities:\n",
    "            return []\n",
    "        sql = []\n",
    "\n",
    "        # 查询症状\n",
    "        if intent == \"query_symptom\" and label == \"Disease\":\n",
    "            sql = [\"MATCH (d:Disease)-[:HAS_SYMPTOM]->(s) WHERE d.name='{0}' RETURN d.name,s.name\".format(e)\n",
    "                   for e in entities]\n",
    "        if intent == \"query_symptom\" and label == \"Alias\":\n",
    "            sql = [\"MATCH (a:Alias)<-[:ALIAS_IS]-(d:Disease)-[:HAS_SYMPTOM]->(s) WHERE a.name='{0}' return \" \\\n",
    "                   \"d.name,s.name\".format(e) for e in entities]\n",
    "\n",
    "        # 查询治疗方法\n",
    "        if intent == \"query_cureway\" and label == \"Disease\":\n",
    "            sql = [\"MATCH (d:Disease)-[:HAS_DRUG]->(n) WHERE d.name='{0}' return d.name,d.treatment,\" \\\n",
    "                   \"n.name\".format(e) for e in entities]\n",
    "        if intent == \"query_cureway\" and label == \"Alias\":\n",
    "            sql = [\"MATCH (n)<-[:HAS_DRUG]-(d:Disease)-[]->(a:Alias) WHERE a.name='{0}' \" \\\n",
    "                   \"return d.name, d.treatment, n.name\".format(e) for e in entities]\n",
    "        if intent == \"query_cureway\" and label == \"Symptom\":\n",
    "            sql = [\"MATCH (n)<-[:HAS_DRUG]-(d:Disease)-[]->(s:Symptom) WHERE s.name='{0}' \" \\\n",
    "                   \"return d.name,d.treatment, n.name\".format(e) for e in entities]\n",
    "        if intent == \"query_cureway\" and label == \"Complication\":\n",
    "            sql = [\"MATCH (n)<-[:HAS_DRUG]-(d:Disease)-[]->(c:Complication) WHERE c.name='{0}' \" \\\n",
    "                   \"return d.name,d.treatment, n.name\".format(e) for e in entities]\n",
    "\n",
    "        # 查询治疗周期\n",
    "        if intent == \"query_period\" and label == \"Disease\":\n",
    "            sql = [\"MATCH (d:Disease) WHERE d.name='{0}' return d.name,d.period\".format(e) for e in entities]\n",
    "        if intent == \"query_period\" and label == \"Alias\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(a:Alias) WHERE a.name='{0}' return d.name,d.period\".format(e)\n",
    "                   for e in entities]\n",
    "        if intent == \"query_period\" and label == \"Symptom\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(s:Symptom) WHERE s.name='{0}' return d.name,d.period\".format(e)\n",
    "                   for e in entities]\n",
    "        if intent == \"query_period\" and label == \"Complication\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(c:Complication) WHERE c.name='{0}' return d.name,\" \\\n",
    "                   \"d.period\".format(e) for e in entities]\n",
    "\n",
    "        # 查询治愈率\n",
    "        if intent == \"query_rate\" and label == \"Disease\":\n",
    "            sql = [\"MATCH (d:Disease) WHERE d.name='{0}' return d.name,d.rate\".format(e) for e in entities]\n",
    "        if intent == \"query_rate\" and label == \"Alias\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(a:Alias) WHERE a.name='{0}' return d.name,d.rate\".format(e)\n",
    "                   for e in entities]\n",
    "        if intent == \"query_rate\" and label == \"Symptom\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(s:Symptom) WHERE s.name='{0}' return d.name,d.rate\".format(e)\n",
    "                   for e in entities]\n",
    "        if intent == \"query_rate\" and label == \"Complication\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(c:Complication) WHERE c.name='{0}' return d.name,\" \\\n",
    "                   \"d.rate\".format(e) for e in entities]\n",
    "\n",
    "        # 查询检查项目\n",
    "        if intent == \"query_checklist\" and label == \"Disease\":\n",
    "            sql = [\"MATCH (d:Disease) WHERE d.name='{0}' return d.name,d.checklist\".format(e) for e in entities]\n",
    "        if intent == \"query_checklist\" and label == \"Alias\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(a:Alias) WHERE a.name='{0}' return d.name,d.checklist\".format(e)\n",
    "                   for e in entities]\n",
    "        if intent == \"query_checklist\" and label == \"Symptom\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(s:Symptom) WHERE s.name='{0}' return d.name,\" \\\n",
    "                   \"d.checklist\".format(e) for e in entities]\n",
    "        if intent == \"query_checklist\" and label == \"Complication\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(c:Complication) WHERE c.name='{0}' return d.name,\" \\\n",
    "                   \"d.checklist\".format(e) for e in entities]\n",
    "\n",
    "        # 查询科室\n",
    "        if intent == \"query_department\" and label == \"Disease\":\n",
    "            sql = [\"MATCH (d:Disease)-[:DEPARTMENT_IS]->(n) WHERE d.name='{0}' return d.name,\" \\\n",
    "                   \"n.name\".format(e) for e in entities]\n",
    "        if intent == \"query_department\" and label == \"Alias\":\n",
    "            sql = [\"MATCH (n)<-[:DEPARTMENT_IS]-(d:Disease)-[:ALIAS_IS]->(a:Alias) WHERE a.name='{0}' \" \\\n",
    "                   \"return d.name,n.name\".format(e) for e in entities]\n",
    "        if intent == \"query_department\" and label == \"Symptom\":\n",
    "            sql = [\"MATCH (n)<-[:DEPARTMENT_IS]-(d:Disease)-[:HAS_SYMPTOM]->(s:Symptom) WHERE s.name='{0}' \" \\\n",
    "                   \"return d.name,n.name\".format(e) for e in entities]\n",
    "        if intent == \"query_department\" and label == \"Complication\":\n",
    "            sql = [\"MATCH (n)<-[:DEPARTMENT_IS]-(d:Disease)-[:HAS_COMPLICATION]->(c:Complication) WHERE \" \\\n",
    "                   \"c.name='{0}' return d.name,n.name\".format(e) for e in entities]\n",
    "\n",
    "        # 查询疾病\n",
    "        if intent == \"query_disease\" and label == \"Alias\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(s:Alias) WHERE s.name='{0}' return \" \\\n",
    "                   \"d.name\".format(e) for e in entities]\n",
    "        if intent == \"query_disease\" and label == \"Symptom\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(s:Symptom) WHERE s.name='{0}' return \" \\\n",
    "                   \"d.name\".format(e) for e in entities]\n",
    "\n",
    "        # 查询疾病描述\n",
    "        if intent == \"disease_describe\" and label == \"Alias\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(a:Alias) WHERE a.name='{0}' return d.name,d.age,\" \\\n",
    "                   \"d.insurance,d.infection,d.checklist,d.period,d.rate,d.money\".format(e) for e in entities]\n",
    "        if intent == \"disease_describe\" and label == \"Disease\":\n",
    "            sql = [\"MATCH (d:Disease) WHERE d.name='{0}' return d.name,d.age,d.insurance,d.infection,\" \\\n",
    "                   \"d.checklist,d.period,d.rate,d.money\".format(e) for e in entities]\n",
    "        if intent == \"disease_describe\" and label == \"Symptom\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(s:Symptom) WHERE s.name='{0}' return d.name,d.age,\" \\\n",
    "                   \"d.insurance,d.infection,d.checklist,d.period,d.rate,d.money\".format(e) for e in entities]\n",
    "        if intent == \"disease_describe\" and label == \"Complication\":\n",
    "            sql = [\"MATCH (d:Disease)-[]->(c:Complication) WHERE c.name='{0}' return d.name,\" \\\n",
    "                   \"d.age,d.insurance,d.infection,d.checklist,d.period,d.rate,d.money\".format(e) for e in entities]\n",
    "\n",
    "        return sql\n",
    "\n",
    "    def searching(self, sqls):\n",
    "        \"\"\"\n",
    "        执行cypher查询，返回结果\n",
    "        :param sqls:\n",
    "        :return:str\n",
    "        \"\"\"\n",
    "        final_answers = []\n",
    "        for sql_ in sqls:\n",
    "            intent = sql_['intention']\n",
    "            queries = sql_['sql']\n",
    "            answers = []\n",
    "            for query in queries:\n",
    "                ress = self.graph.run(query).data()\n",
    "                answers += ress\n",
    "            final_answer = self.answer_template(intent, answers)\n",
    "            if final_answer:\n",
    "                final_answers.append(final_answer)\n",
    "        return final_answers\n",
    "\n",
    "    def answer_template(self, intent, answers):\n",
    "        \"\"\"\n",
    "        根据不同意图，返回不同模板的答案\n",
    "        :param intent: 查询意图\n",
    "        :param answers: 知识图谱查询结果\n",
    "        :return: str\n",
    "        \"\"\"\n",
    "        final_answer = \"\"\n",
    "        if not answers:\n",
    "            return \"\"\n",
    "        # 查询症状\n",
    "        if intent == \"query_symptom\":\n",
    "            disease_dic = {}\n",
    "            for data in answers:\n",
    "                d = data['d.name']\n",
    "                s = data['s.name']\n",
    "                if d not in disease_dic:\n",
    "                    disease_dic[d] = [s]\n",
    "                else:\n",
    "                    disease_dic[d].append(s)\n",
    "            i = 0\n",
    "            for k, v in disease_dic.items():\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                final_answer += \"疾病 {0} 的症状有：{1}\\n\".format(k, ','.join(list(set(v))))\n",
    "                i += 1\n",
    "        # 查询疾病\n",
    "        if intent == \"query_disease\":\n",
    "            disease_freq = {}\n",
    "            for data in answers:\n",
    "                d = data[\"d.name\"]\n",
    "                disease_freq[d] = disease_freq.get(d, 0) + 1\n",
    "            n = len(disease_freq.keys())\n",
    "            freq = sorted(disease_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "            for d, v in freq[:10]:\n",
    "                final_answer += \"疾病为 {0} 的概率为：{1}\\n\".format(d, v/10)\n",
    "        # 查询治疗方法\n",
    "        if intent == \"query_cureway\":\n",
    "            disease_dic = {}\n",
    "            for data in answers:\n",
    "                disease = data['d.name']\n",
    "                treat = data[\"d.treatment\"]\n",
    "                drug = data[\"n.name\"]\n",
    "                if disease not in disease_dic:\n",
    "                    disease_dic[disease] = [treat, drug]\n",
    "                else:\n",
    "                    disease_dic[disease].append(drug)\n",
    "            i = 0\n",
    "            for d, v in disease_dic.items():\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                final_answer += \"疾病 {0} 的治疗方法有：{1}；可用药品包括：{2}\\n\".format(d, v[0], ','.join(v[1:]))\n",
    "                i += 1\n",
    "        # 查询治愈周期\n",
    "        if intent == \"query_period\":\n",
    "            disease_dic = {}\n",
    "            for data in answers:\n",
    "                d = data['d.name']\n",
    "                p = data['d.period']\n",
    "                if d not in disease_dic:\n",
    "                    disease_dic[d] = [p]\n",
    "                else:\n",
    "                    disease_dic[d].append(p)\n",
    "            i = 0\n",
    "            for k, v in disease_dic.items():\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                final_answer += \"疾病 {0} 的治愈周期为：{1}\\n\".format(k, ','.join(list(set(v))))\n",
    "                i += 1\n",
    "        # 查询治愈率\n",
    "        if intent == \"query_rate\":\n",
    "            disease_dic = {}\n",
    "            for data in answers:\n",
    "                d = data['d.name']\n",
    "                r = data['d.rate']\n",
    "                if d not in disease_dic:\n",
    "                    disease_dic[d] = [r]\n",
    "                else:\n",
    "                    disease_dic[d].append(r)\n",
    "            i = 0\n",
    "            for k, v in disease_dic.items():\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                final_answer += \"疾病 {0} 的治愈率为：{1}\\n\".format(k, ','.join(list(set(v))))\n",
    "                i += 1\n",
    "        # 查询检查项目\n",
    "        if intent == \"query_checklist\":\n",
    "            disease_dic = {}\n",
    "            for data in answers:\n",
    "                d = data['d.name']\n",
    "                r = data['d.checklist']\n",
    "                if d not in disease_dic:\n",
    "                    disease_dic[d] = [r]\n",
    "                else:\n",
    "                    disease_dic[d].append(r)\n",
    "            i = 0\n",
    "            for k, v in disease_dic.items():\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                final_answer += \"疾病 {0} 的检查项目有：{1}\\n\".format(k, ','.join(list(set(v))))\n",
    "                i += 1\n",
    "        # 查询科室\n",
    "        if intent == \"query_department\":\n",
    "            disease_dic = {}\n",
    "            for data in answers:\n",
    "                d = data['d.name']\n",
    "                r = data['n.name']\n",
    "                if d not in disease_dic:\n",
    "                    disease_dic[d] = [r]\n",
    "                else:\n",
    "                    disease_dic[d].append(r)\n",
    "            i = 0\n",
    "            for k, v in disease_dic.items():\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                final_answer += \"疾病 {0} 所属科室有：{1}\\n\".format(k, ','.join(list(set(v))))\n",
    "                i += 1\n",
    "        # 查询疾病描述\n",
    "        if intent == \"disease_describe\":\n",
    "            disease_infos = {}\n",
    "            for data in answers:\n",
    "                name = data['d.name']\n",
    "                age = data['d.age']\n",
    "                insurance = data['d.insurance']\n",
    "                infection = data['d.infection']\n",
    "                checklist = data['d.checklist']\n",
    "                period = data['d.period']\n",
    "                rate = data['d.rate']\n",
    "                money = data['d.money']\n",
    "                if name not in disease_infos:\n",
    "                    disease_infos[name] = [age, insurance, infection, checklist, period, rate, money]\n",
    "                else:\n",
    "                    disease_infos[name].extend([age, insurance, infection, checklist, period, rate, money])\n",
    "            i = 0\n",
    "            for k, v in disease_infos.items():\n",
    "                if i >= 10:\n",
    "                    break\n",
    "                message = \"疾病 {0} 的描述信息如下：\\n发病人群：{1}\\n医保：{2}\\n传染性：{3}\\n检查项目：{4}\\n\" \\\n",
    "                          \"治愈周期：{5}\\n治愈率：{6}\\n费用：{7}\\n\"\n",
    "                final_answer += message.format(k, v[0], v[1], v[2], v[3], v[4], v[5], v[6])\n",
    "                i += 1\n",
    "\n",
    "        return final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kbqa_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "\n",
    "#from entity_extractor import EntityExtractor\n",
    "#from search_answer import AnswerSearching\n",
    "\n",
    "\n",
    "class KBQA:\n",
    "    def __init__(self):\n",
    "        self.extractor = EntityExtractor()\n",
    "        self.searcher = AnswerSearching()\n",
    "\n",
    "    def qa_main(self, input_str):\n",
    "        answer = \"对不起，您的问题我不知道，我今后会努力改进的。\"\n",
    "        entities = self.extractor.extractor(input_str)\n",
    "        if not entities:\n",
    "            return answer\n",
    "        sqls = self.searcher.question_parser(entities)\n",
    "        final_answer = self.searcher.searching(sqls)\n",
    "        if not final_answer:\n",
    "            return answer\n",
    "        else:\n",
    "            return '\\n'.join(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cc895c80a0c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKBQA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-00b6d2277667>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mKBQA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntityExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnswerSearching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-39f86973b6c3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfidf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model/tfidf_model.m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model/intent_reg_model.m'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#朴素贝叶斯模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfidf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfidf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "handler = KBQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    while True:\n",
    "        question = input(\"用户：\")\n",
    "        if not question:\n",
    "            break\n",
    "        answer = handler.qa_main(question)\n",
    "        print(\"小豪：\", answer)\n",
    "        print(\"*\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
